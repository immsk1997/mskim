args:{'scheduler': 'CosineAnnealingLR', 'T_max': 10, 'T_0': 10, 'lr': 0.0001, 'min_lr': 1e-06, 'weight_decay': 1e-05, 'n_fold': 10, 'smoothing': 0.3, 
'batch_size': 16, 'net_architect': 'VisionTransformer', 'finetuning_type': 'classifier', 'compart_name': 'resized', 
'sequence': ['t1', 't2', 't1ce', 'flair'],
 'data_key_list': ['sex', 'age', 'IDH', 'glioma_type', 'glioma_num', 'MGMT', 'GBL', 'EOR', 'duration_death', 'event_death', 'duration_prog', 'event_prog', 'biopsy_exclusion'
 ], 'root_dir': '/mnt/hdd3/mskim/GBL', 'data_dir': '/mnt/hdd3/mskim/GBL/data', 'label_dir': '/mnt/hdd3/mskim/GBL/data/label/surv_labels',
  'proc_label_dir': '/mnt/hdd3/mskim/GBL/data/label/surv_labels/proc_labels', 'exp_dir': '/mnt/hdd3/mskim/GBL/code/experiment', 'dataset_name': ''}
Using VisionTransformer
Train dataset_name:UCSF_UPenn_TCGA_severance
Training on GPU 0
Setting seed:123456
dataset:UCSF for training
df_dataset.shape:(500, 13)
dataset:UPenn for training
df_dataset.shape:(425, 13)
dataset:TCGA for training
df_dataset.shape:(160, 13)
dataset:severance for training
df_dataset.shape:(132, 13)
df_label_dataset_list.shape:(1217, 13)
events before 1yr:
910
events after 1yr:
442
ext_df_dataset.shape:(1013, 13)
events before 1yr:
1298
events after 1yr:
867
df.index.values:1217
list_dataset: ['UCSF', 'UPenn', 'TCGA', 'severance']
split_dataset: UCSF
split_img_label_comm_list:494
split_dataset: UPenn
split_img_label_comm_list:383
split_dataset: TCGA
split_img_label_comm_list:136
split_dataset: severance
split_img_label_comm_list:132
img_label_comm_list:1145
dataset_name:UCSF_UPenn_TCGA_severance, 1145
UCSF_UPenn_TCGA_severance df.shape: (1145, 13)
df.index.values:1013
img_label_comm_list:1011
dataset_name:SNUH, 1011
SNUH df.shape: (1011, 13)
df.index.values:1217
list_dataset: ['UCSF', 'UPenn', 'TCGA', 'severance']
split_dataset: UCSF
split_img_label_comm_list:494
split_dataset: UPenn
split_img_label_comm_list:383
split_dataset: TCGA
split_img_label_comm_list:136
split_dataset: severance
split_img_label_comm_list:132
img_label_comm_list:1145
dataset_name:UCSF_UPenn_TCGA_severance, 1145
UCSF_UPenn_TCGA_severance df.shape: (1145, 13)
num of train_data: 1145
Epoch 1/50
----------
phase:train
train Loss: 1.1990

Epoch 2/50
----------
phase:train
train Loss: 1.1160

Epoch 3/50
----------
phase:train
train Loss: 1.1154

Epoch 4/50
----------
phase:train
train Loss: 1.1155

Epoch 5/50
----------
phase:train
train Loss: 1.1144

Epoch 6/50
----------
phase:train
train Loss: 1.1126

Epoch 7/50
----------
phase:train
train Loss: 1.1126

Epoch 8/50
----------
phase:train
train Loss: 1.1105

Epoch 9/50
----------
phase:train
train Loss: 1.1107

Epoch 10/50
----------
phase:train
train Loss: 1.1097

Epoch 11/50
----------
phase:train
train Loss: 1.1095

Epoch 12/50
----------
phase:train
train Loss: 1.1099

Epoch 13/50
----------
phase:train
train Loss: 1.1102

Epoch 14/50
----------
phase:train
train Loss: 1.1109

Epoch 15/50
----------
phase:train
train Loss: 1.1126

Epoch 16/50
----------
phase:train
train Loss: 1.1120

Epoch 17/50
----------
phase:train
train Loss: 1.1119

Epoch 18/50
----------
phase:train
train Loss: 1.1180

Epoch 19/50
----------
phase:train
train Loss: 1.1097

Epoch 20/50
----------
phase:train
train Loss: 1.1062

Epoch 21/50
----------
phase:train
train Loss: 1.1044

Epoch 22/50
----------
phase:train
train Loss: 1.0955

Epoch 23/50
----------
phase:train
train Loss: 1.0906

Epoch 24/50
----------
phase:train
train Loss: 1.0791

Epoch 25/50
----------
phase:train
train Loss: 1.0666

Epoch 26/50
----------
phase:train
train Loss: 1.0538

Epoch 27/50
----------
phase:train
train Loss: 1.0223

Epoch 28/50
----------
phase:train
train Loss: 0.9992

Epoch 29/50
----------
phase:train
train Loss: 0.9768

Epoch 30/50
----------
phase:train
train Loss: 0.9593

Epoch 31/50
----------
phase:train
train Loss: 0.9533

Epoch 32/50
----------
phase:train
train Loss: 0.9519

Epoch 33/50
----------
phase:train
train Loss: 0.9505

Epoch 34/50
----------
phase:train
train Loss: 0.9534

Epoch 35/50
----------
phase:train
train Loss: 0.9450

Epoch 36/50
----------
phase:train
train Loss: 0.9474

Epoch 37/50
----------
phase:train
train Loss: 0.9490

Epoch 38/50
----------
phase:train
train Loss: 0.9452

Epoch 39/50
----------
phase:train
train Loss: 0.9253

Epoch 40/50
----------
phase:train
train Loss: 0.9163

Epoch 41/50
----------
phase:train
train Loss: 0.9025

Epoch 42/50
----------
phase:train
train Loss: 0.8947

Epoch 43/50
----------
phase:train
train Loss: 0.8757

Epoch 44/50
----------
phase:train
train Loss: 0.8420

Epoch 45/50
----------
phase:train
train Loss: 0.8398

Epoch 46/50
----------
phase:train
train Loss: 0.8160

Epoch 47/50
----------
phase:train
train Loss: 0.7972

Epoch 48/50
----------
phase:train
train Loss: 0.7906

Epoch 49/50
----------
phase:train
train Loss: 0.7864

Epoch 50/50
----------
phase:train
train Loss: 0.7856

Training complete in 3h 4m 4s
Best Loss  0.785603906181702
latest_ckpt_model: /mnt/hdd3/mskim/GBL/code/saved_models/VisionTransformer/06_01_14_01_VisionTransformer_epoch50.pth
num of train_data: 1030
num of valid_data: 115
Epoch 1/50
----------
phase:train
train Loss: 2.9104
phase:valid
valid Loss: 1.6795

Epoch 2/50
----------
phase:train
train Loss: 1.5068
phase:valid
valid Loss: 1.3876

Epoch 3/50
----------
phase:train
train Loss: 1.3420
phase:valid
valid Loss: 1.3166

Epoch 4/50
----------
phase:train
train Loss: 1.2934
phase:valid
valid Loss: 1.2874

Epoch 5/50
----------
phase:train
train Loss: 1.2722
phase:valid
valid Loss: 1.2763

Epoch 6/50
----------
phase:train
train Loss: 1.2593
phase:valid
valid Loss: 1.2668

Epoch 7/50
----------
phase:train
train Loss: 1.2511
phase:valid
valid Loss: 1.2608

Epoch 8/50
----------
phase:train
train Loss: 1.2466
phase:valid
valid Loss: 1.2583

Epoch 9/50
----------
phase:train
train Loss: 1.2446
phase:valid
valid Loss: 1.2585

Epoch 10/50
----------
phase:train
train Loss: 1.2425
phase:valid
valid Loss: 1.2581

Epoch 11/50
----------
phase:train
train Loss: 1.2421
phase:valid
valid Loss: 1.2580

Epoch 12/50
----------
phase:train
train Loss: 1.2420
phase:valid
valid Loss: 1.2574

Epoch 13/50
----------
phase:train
train Loss: 1.2419
phase:valid
valid Loss: 1.2556

Epoch 14/50
----------
phase:train
train Loss: 1.2411
phase:valid
valid Loss: 1.2537

Epoch 15/50
----------
phase:train
train Loss: 1.2384
phase:valid
valid Loss: 1.2496

Epoch 16/50
----------
phase:train
train Loss: 1.2352
phase:valid
valid Loss: 1.2452

Epoch 17/50
----------
phase:train
train Loss: 1.2327
phase:valid
valid Loss: 1.2410

Epoch 18/50
----------
phase:train
train Loss: 1.2295
phase:valid
valid Loss: 1.2427

Epoch 19/50
----------
phase:train
train Loss: 1.2296
phase:valid
valid Loss: 1.2414

Epoch 20/50
----------
phase:train
train Loss: 1.2285
phase:valid
valid Loss: 1.2275

Epoch 21/50
----------
phase:train
train Loss: 1.2217
phase:valid
valid Loss: 1.2350

Epoch 22/50
----------
phase:train
train Loss: 1.2218
phase:valid
valid Loss: 1.2355

Epoch 23/50
----------
phase:train
train Loss: 1.2199
phase:valid
valid Loss: 1.2331

Epoch 24/50
----------
phase:train
train Loss: 1.2175
phase:valid
valid Loss: 1.2280

Epoch 25/50
----------
phase:train
train Loss: 1.2148
phase:valid
valid Loss: 1.2266

Epoch 26/50
----------
phase:train
train Loss: 1.2114
phase:valid
valid Loss: 1.2284

Epoch 27/50
----------
phase:train
train Loss: 1.2097
phase:valid
valid Loss: 1.2327

Epoch 28/50
----------
phase:train
train Loss: 1.2084
phase:valid
valid Loss: 1.2312

Epoch 29/50
----------
phase:train
train Loss: 1.2067
phase:valid
valid Loss: 1.2308

Epoch 30/50
----------
phase:train
train Loss: 1.2062
phase:valid
valid Loss: 1.2311

Epoch 31/50
----------
phase:train
train Loss: 1.2060
phase:valid
valid Loss: 1.2310

Epoch 32/50
----------
phase:train
train Loss: 1.2062
phase:valid
valid Loss: 1.2313

Epoch 33/50
----------
phase:train
train Loss: 1.2068
phase:valid
valid Loss: 1.2309

Epoch 34/50
----------
phase:train
train Loss: 1.2071
phase:valid
valid Loss: 1.2313

Epoch 35/50
----------
phase:train
train Loss: 1.2088
phase:valid
valid Loss: 1.2317

Epoch 36/50
----------
phase:train
train Loss: 1.2085
phase:valid
valid Loss: 1.2304

Epoch 37/50
----------
phase:train
train Loss: 1.2088
phase:valid
valid Loss: 1.2330

Epoch 38/50
----------
phase:train
train Loss: 1.2099
phase:valid
valid Loss: 1.2300

Epoch 39/50
----------
phase:train
train Loss: 1.2118
phase:valid
valid Loss: 1.2376

Epoch 40/50
----------
phase:train
train Loss: 1.2086
phase:valid
valid Loss: 1.2320

Epoch 41/50
----------
phase:train
train Loss: 1.2076
phase:valid
valid Loss: 1.2411

Epoch 42/50
----------
phase:train
train Loss: 1.2103
phase:valid
valid Loss: 1.2306

Epoch 43/50
----------
phase:train
train Loss: 1.2040
phase:valid
valid Loss: 1.2337

Epoch 44/50
----------
phase:train
train Loss: 1.2058
phase:valid
valid Loss: 1.2248

Epoch 45/50
----------
phase:train
train Loss: 1.2018
phase:valid
valid Loss: 1.2294

Epoch 46/50
----------
phase:train
train Loss: 1.2004
phase:valid
valid Loss: 1.2261

Epoch 47/50
----------
phase:train
train Loss: 1.1978
phase:valid
valid Loss: 1.2303

Epoch 48/50
----------
phase:train
train Loss: 1.1968
phase:valid
valid Loss: 1.2304

Epoch 49/50
----------
phase:train
train Loss: 1.1963
phase:valid
valid Loss: 1.2297

Epoch 50/50
----------
phase:train
train Loss: 1.1955
phase:valid
valid Loss: 1.2294

Training complete in 2h 53m 53s
Best Loss  1.2248070177824602
Testing on GPU 1
latest_ckpt_model: /mnt/hdd3/mskim/GBL/code/saved_models/VisionTransformer/06_01_17_01_VisionTransformer_epoch44.pth
y_pred.size:torch.Size([1, 19])
y_pred:tensor([[0.9521, 0.9112, 0.9179, 0.9027, 0.8784, 0.8678, 0.9998, 0.9997, 0.9997,
         0.9997, 0.9996, 0.9996, 0.9996, 0.9994, 0.9991, 0.9986, 0.9979, 0.7702,
         0.9171]], device='cuda:1', grad_fn=<PowBackward1>)
labels.size:torch.Size([1, 38])
labels:tensor([[1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,
         0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0]], device='cuda:1')
subj_num:0
oneyr_surv_test: [0.547951]
y_pred.size:torch.Size([1, 19])
y_pred:tensor([[0.9983, 0.9798, 0.9753, 0.9557, 0.9630, 0.9849, 0.9997, 0.9997, 0.9997,
         0.9998, 0.9997, 0.9998, 0.9998, 0.9997, 0.9998, 0.9997, 0.9992, 0.9979,
         0.9973]], device='cuda:1', grad_fn=<PowBackward1>)
labels.size:torch.Size([1, 38])
labels:tensor([[1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,
         0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1]], device='cuda:1')
subj_num:1
oneyr_surv_test: [0.86469966]
y_pred.size:torch.Size([1, 19])
y_pred:tensor([[0.9985, 0.9823, 0.9770, 0.9673, 0.9599, 0.9713, 0.9997, 0.9997, 0.9996,
         0.9997, 0.9997, 0.9997, 0.9997, 0.9996, 0.9996, 0.9996, 0.9987, 0.9953,
         0.9941]], device='cuda:1', grad_fn=<PowBackward1>)
labels.size:torch.Size([1, 38])
labels:tensor([[1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,
         0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1]], device='cuda:1')
subj_num:2
oneyr_surv_test: [0.8641805]
y_pred.size:torch.Size([1, 19])
y_pred:tensor([[0.9685, 0.9371, 0.9452, 0.9436, 0.9074, 0.8744, 0.9999, 0.9998, 0.9998,
         0.9998, 0.9998, 0.9998, 0.9998, 0.9997, 0.9995, 0.9990, 0.9987, 0.8263,
         0.9427]], device='cuda:1', grad_fn=<PowBackward1>)
labels.size:torch.Size([1, 38])
labels:tensor([[1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,
         0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1]], device='cuda:1')
subj_num:3
oneyr_surv_test: [0.6422381]
y_pred.size:torch.Size([1, 19])
y_pred:tensor([[0.9529, 0.9296, 0.9166, 0.9146, 0.9148, 0.9209, 0.9998, 0.9998, 0.9998,
         0.9998, 0.9997, 0.9997, 0.9998, 0.9996, 0.9993, 0.9992, 0.9989, 0.9046,
         0.9633]], device='cuda:1', grad_fn=<PowBackward1>)
labels.size:torch.Size([1, 38])
labels:tensor([[1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,
         0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0]], device='cuda:1')
subj_num:4
oneyr_surv_test: [0.625623]
y_pred.size:torch.Size([1, 19])
y_pred:tensor([[0.9745, 0.9283, 0.9256, 0.9136, 0.9041, 0.9041, 0.9998, 0.9997, 0.9998,
         0.9998, 0.9997, 0.9996, 0.9997, 0.9996, 0.9991, 0.9988, 0.9983, 0.8239,
         0.9236]], device='cuda:1', grad_fn=<PowBackward1>)
labels.size:torch.Size([1, 38])
labels:tensor([[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,
         0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1]], device='cuda:1')
subj_num:5
oneyr_surv_test: [0.6252924]
y_pred.size:torch.Size([1, 19])
y_pred:tensor([[0.9412, 0.9298, 0.9117, 0.8951, 0.8964, 0.9088, 0.9998, 0.9997, 0.9997,
         0.9997, 0.9997, 0.9997, 0.9997, 0.9994, 0.9992, 0.9989, 0.9984, 0.8728,
         0.9488]], device='cuda:1', grad_fn=<PowBackward1>)
labels.size:torch.Size([1, 38])
labels:tensor([[1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,
         0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1]], device='cuda:1')
subj_num:6
oneyr_surv_test: [0.5817419]
y_pred.size:torch.Size([1, 19])
y_pred:tensor([[0.9807, 0.9417, 0.9226, 0.9140, 0.9398, 0.9110, 0.9989, 0.9983, 0.9991,
         0.9987, 0.9991, 0.9976, 0.9983, 0.9986, 0.9959, 0.9922, 0.9896, 0.9515,
         0.9633]], device='cuda:1', grad_fn=<PowBackward1>)
labels.size:torch.Size([1, 38])
labels:tensor([[1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,
         0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0]], device='cuda:1')
subj_num:7
oneyr_surv_test: [0.6667347]
y_pred.size:torch.Size([1, 19])
y_pred:tensor([[0.9627, 0.9249, 0.9356, 0.9198, 0.8964, 0.8826, 0.9998, 0.9998, 0.9998,
         0.9998, 0.9998, 0.9997, 0.9997, 0.9996, 0.9994, 0.9991, 0.9986, 0.8070,
         0.9434]], device='cuda:1', grad_fn=<PowBackward1>)
labels.size:torch.Size([1, 38])
labels:tensor([[1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1,
         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]], device='cuda:1')
subj_num:8
oneyr_surv_test: [0.60618377]
y_pred.size:torch.Size([1, 19])
y_pred:tensor([[0.9628, 0.9131, 0.9349, 0.8988, 0.8885, 0.9091, 0.9997, 0.9997, 0.9997,
         0.9997, 0.9996, 0.9996, 0.9997, 0.9995, 0.9992, 0.9991, 0.9986, 0.8193,
         0.9367]], device='cuda:1', grad_fn=<PowBackward1>)
labels.size:torch.Size([1, 38])
labels:tensor([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:1')
subj_num:9
oneyr_surv_test: [0.5967177]
y_pred.size:torch.Size([1, 19])
y_pred:tensor([[0.9697, 0.9354, 0.9418, 0.9449, 0.9081, 0.9002, 0.9999, 0.9999, 0.9998,
         0.9999, 0.9998, 0.9998, 0.9998, 0.9997, 0.9996, 0.9994, 0.9991, 0.8685,
         0.9583]], device='cuda:1', grad_fn=<PowBackward1>)
labels.size:torch.Size([1, 38])
labels:tensor([[1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,
         0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0]], device='cuda:1')
subj_num:10
oneyr_surv_test: [0.65982836]
y_pred.size:torch.Size([1, 19])
y_pred:tensor([[0.9965, 0.9418, 0.9718, 0.9573, 0.9371, 0.9809, 0.9991, 0.9993, 0.9993,
         0.9993, 0.9990, 0.9993, 0.9992, 0.9992, 0.9995, 0.9993, 0.9992, 0.9969,
         0.9942]], device='cuda:1', grad_fn=<PowBackward1>)
labels.size:torch.Size([1, 38])
labels:tensor([[1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,
         0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1]], device='cuda:1')
...
~ subj_num:1013
...
oneyr_surv_test: [0.78356946]
df_DL_score_test.shape:(1011, 20)
1011
duration_test.shape:(1011,)
oneyr_survs_test.shape:(1011,)
event_test.shape:(1011,)
Original C-index for valid: 0.5057
95% CI for C-index for valid: (0.4691, 0.5445)
BS score at 365:[0.18959395]
