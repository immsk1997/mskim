# -*- coding: utf-8 -*-
"""prototype

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14ufpqbzCZLOZV0CJ2S1YXEpegm-HADOb

# 진행상황
1. underfitting 해결
> pre-train 모델 weights 전부 freezing 했습니다.

2. 데이터 전처리 / 데이터 증강 실시 해야할 것으로 보임

3. flatten 이후 output layer 단계 간소화
> 누가 MLP Layer를 그렇게나 많이 넣은건지..
> output layer cnn 알고리즘 아키텍쳐 방식대로 단순 구현해둔 상태

# 현재까지 결과
1. training accuracy 어느정도 잡았습니다. (지속적으로 상승 중)
2. validation의 경우 max accuracy 달성 후 하향 (14 epoch 부터 정확도 고정)

# 향후 고려사항
1. 지금 모델이 너무 단순해서 좋은 방법론들을 찾아보면 좋을 것 같음
"""

# xml 파싱
import xml.etree.ElementTree as ET
import os

# - CV(Computer Vision)
# > 비전핵 탐지 (#ObjectDetection #ActiveLearning)
# > 유해 이미지 탐지 (#ImageClassification)

dataFile_p = '/content/drive/MyDrive/불량판정 프로젝트/2번 카메라 데이터/사진'
dataFile_t = '/content/drive/MyDrive/불량판정 프로젝트/2번 카메라 데이터/설명'

class0File = '/content/drive/MyDrive/불량판정 프로젝트/2번 카메라 데이터/불량분류/정상'
class1File = '/content/drive/MyDrive/불량판정 프로젝트/2번 카메라 데이터/불량분류/불량 1'
class2File = '/content/drive/MyDrive/불량판정 프로젝트/2번 카메라 데이터/불량분류/불량 2'
class3File = '/content/drive/MyDrive/불량판정 프로젝트/2번 카메라 데이터/불량분류/불량 3'

dataFiles_t = os.listdir(dataFile_t)

p_code = '.jpg'
for s in dataFiles_t:
  p = s.split('.')[0] + p_code

  """ 분류 자동화 간 오류 발생하여 로그 확인용"""
  if p == '.jpg':
    continue

  xmlname = dataFile_t + '/' + s
  imgname = dataFile_p + '/' + p
  img = Image.open(imgname)
  img_resize = img.resize((224, 224))
  tree = ET.parse(xmlname)
  root=tree.getroot()
  tag_list = []
  for i in root:
    tag_list.append(i.tag)
  if len(tag_list) == 6:
    img_resize.save(class0File+ '/' + p)
  elif len(tag_list) == 7:
    class_num = int(tree.find("object")[0].text)
    if class_num == 1:
      img_resize.save(class1File+ '/' + p)
    elif class_num == 2:
      img_resize.save(class2File+ '/' + p)
    elif class_num == 3:
      img_resize.save(class3File+ '/' + p)

# 해당 경로의 파일이나 폴더 삭제(필요 시 사용)
import shutil
shutil.rmtree('/content/drive/MyDrive/불량판정 프로젝트/.ipynb_checkpoints')

import keras # 케라스 라이브러리
import tensorflow as tf # tensorflow 프레임워크

from keras.preprocessing.image import ImageDataGenerator # 이미지 증강
from keras.models import Sequential # sequential 모델
from keras.layers import Dense # dense layer층

from keras.applications import VGG16
from keras.applications import vgg16
from keras.applications import vgg19
from tensorflow.keras.applications import ResNet101
from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions

from tensorflow.keras.preprocessing.image import load_img, img_to_array
from keras.applications.vgg16 import preprocess_input #1 모델 호출을 위한 데이터 전처리, #2 -255에서 255 사이 값으로 정규화를 하고 RGB를 BGR 순서로 바꾼다. #3 preprocess가 끝난 것이 image에 들어간다
from keras.layers import Dense, GlobalAveragePooling2D, Dropout, Flatten
from keras import layers
from tensorflow.keras.optimizers import Adam # 활성화 함수 ADAM
from keras.models import Model
from keras import models
print(tf.__version__)

num_classes = 4
image_size = 224

# imagedatagenerator : 원천 이미지 데이터 가져오기 & 증강, 전처리 기법 적용 동시 수행 객체
data_generator=ImageDataGenerator(preprocessing_function=preprocess_input)
validation_datagen = ImageDataGenerator(preprocessing_function = preprocess_input)

"""TIP : 파이프라인을 사용하면 데이터 사전 처리 및 분류, 모든 단계를 포함한 단일 개체 생성 가능!

그에 따라 train, test 데이터 손실을 피할 수 있으며, 교차검증 및 모델 선택 유형을 쉽게 해준다.

#Train set
"""

# 학습 데이터셋 선언 및 로드
trainDir = '/content/drive/MyDrive/불량판정 프로젝트/2번 카메라 데이터/불량분류 전처리'
train_set = data_generator.flow_from_directory(
    trainDir,
    target_size=(image_size, image_size),
    batch_size=80,
    class_mode='categorical'
    )

x_train, y_train = next(train_set)
len(x_train)

"""# Valid Set"""

# 검증 데이터셋 선언 및 로드
testDir = '/content/drive/MyDrive/불량판정 프로젝트/2번 카메라 데이터/테스트 데이터'
test_set = validation_datagen.flow_from_directory(
    testDir,
    target_size=(image_size, image_size),
    batch_size=30,
    class_mode='categorical'
    )

x_test, y_test = next(test_set)
len(x_test)

print('x_train', x_train.shape)
print('y_train', y_train.shape)
print('x_test', x_test.shape)
print('y_test', y_test.shape)

import matplotlib.pyplot as plt

plt.imshow(x_train[3])

"""# Model"""

conv_layers = VGG16(include_top=False, pooling='max', weights='imagenet',input_shape = (224,224,3))
# include_top : 완전 연결된 뉴런층의 포함 여부를 설정
# weights : None: 임의로 초기화 (random initialization)된 가중치를 적용합니다.
#         : imagenet: ImageNet에 대해 사전 훈련된 가중치를 적용합니다. (Default)

conv_layers.summary()

model = models.Sequential()

model.add(conv_layers)

model.add(layers.Flatten())

model.add(layers.Dropout(0.5))
model.add(layers.Dense(128, activation='relu'))
model.add(keras.layers.BatchNormalization())

model.add(layers.Dense(4, activation='softmax'))

model.summary()

for layer in conv_layers.layers:
    layer.trainable = False
# layer.trainable : 뉴런층의 가중치의 훈련 가능 여부를 설정
# layer.trainable = False -> 레이어 동결 : 모든 레이어의 가중치가 훈련 불가능으로 변경

print(conv_layers.input_shape)
print(conv_layers.output_shape)

# 전처리 x , 증강 x (원본사진 vgg16)
model.compile(loss='sparse_categorical_crossentropy',
            optimizer = Adam(learning_rate=1e-2),
            metrics=['accuracy']) # metrics(척도) : 어떤 모델을 평가하기 위해 사용하는 값
hist=model.fit(x_train, y_train, batch_size=100, epochs=20, validation_split=0.3)

"""# Results"""

# vgg16 훈련 정확도
res = model.evaluate(x_train, y_train)
print(f'정확도={res[1]*100:.1f}%')

# vgg16 모델 정확도
res = model.evaluate(x_test, y_test)
print(f'정확도={res[1]*100:.1f}%')

import matplotlib.pyplot as plt

# train(학습,훈련) , validation(모델성능) 정확율
plt.plot(hist.history['accuracy'])
plt.plot(hist.history['val_accuracy'])
plt.title('VGG16')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Validataion'], loc = 'lower right')
plt.grid()
plt.show()

# 학습, 모델성능 Data Loss rate
plt.plot(hist.history['loss'])
plt.plot(hist.history['val_loss'])
plt.title("vgg16 Loss rate")
plt.xlabel("epoch")
plt.ylabel("Loss")
plt.legend(['Train','Validation'], loc = 'lower right')
plt.grid()
plt.show()